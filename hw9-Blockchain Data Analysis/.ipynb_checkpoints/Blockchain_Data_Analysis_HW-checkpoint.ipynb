{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â Blockchain Data Analysis: Exploring transactions between miners in Ethereum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most contentious issues in the Blockchain space concerns the independence and stability of the transaction validators that participate in the consensus protocol. In Proof-of-Work (PoW) Blockchains these _validators_ are called **miners**. The specialization and centralization of mining across different PoW systems has been well documented in the last few years. High centralization of mining, undermines the central premise of blockchain systems by making the system: \n",
    "1. more vulnerable to central points of failure and \n",
    "2. more vulnerable to the larger miners manipulating transactions on their behalf (see [Selfish Mining](https://www.binance.vision/glossary/selfish-mining), [51% Attacks](https://www.binance.vision/security/what-is-a-51-percent-attack) and [Transaction Frontrunning](https://arxiv.org/pdf/1904.05234.pdf)). \n",
    "\n",
    "Eventhough the individual mining power can be readily observed by looking at how many blocks has each miner mined, there might still exist collusion agreements or other types of relationships between miners, that are less aparent. This notebook intents to explore transactions between miners in Ethereum to try to characterize potential relationships between miners. \n",
    "\n",
    "In the notebook you will: \n",
    "\n",
    "\n",
    "- Explore the evolution of the Etheruem mining ecosystem\n",
    "- Pre-process data to create a transaction graph object\n",
    "- Visualize transaction graph data\n",
    "- Perform basic network analysis over the transaction graph\n",
    "\n",
    "This notebook assumes basic understanding of [numpy arrays](https://cs231n.github.io/python-numpy-tutorial/#arrays) and [pandas DataFrame](https://pandas.pydata.org/pandas-docs/stable/getting_started/dsintro.html) data structures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import percentileofscore\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Exploring the evolution of the Ethereum miner ecosystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the ./data folder of our repo, we have compiled 51 snapshots of the Ethereum miner transaction network that cover transactions in 8,863,264 blocks (since the launch of Ethereum in July 30 2015 to November 3 2019). Each snapshot is stored as a Pandas DataFrame that aggregates blocks mined in increments of 170,822 blocks (roughly the number of blocks mined every month). All snapshots are stored in a list of DataFrames. The data is extracted below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'files_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e1b2033ad4e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfiles_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mroot_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mfile_path_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfile\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mfile_path_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'files_list' is not defined"
     ]
    }
   ],
   "source": [
    "# LOAD DATACreate dataframes from CSV files\n",
    "for (root,dirs,files) in os.walk(\n",
    "    './data/miner_volume', topdown=True):\n",
    "    files_list=files\n",
    "    root_dir=root\n",
    "file_path_list=[root_dir+'/'+file for file in files_list]\n",
    "file_path_list.sort()\n",
    "\n",
    "miner_summaries=[pd.read_csv(file_path).drop(columns='Unnamed: 0') for file_path in file_path_list] #Load each summary (slice) in list\n",
    "\n",
    "for df in miner_summaries: # Edit miners with null blocks\n",
    "    df.loc[df['block'].isnull(),'block']=1\n",
    "# Final list with miner summary dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example the first 5 rows of the DataFrame for the 5th snapshot are shown below. This DataFrame aggregates information for the first 854,110 (170,822 x 5) blocks: \n",
    "- **miner**: The miner's public address. \n",
    "- **block**: The number of blocks mined by that miner up until block 854,110\n",
    "- **transaction_count**: The number of transactions mined by that miner up until block 854,110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miner_summaries[5].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concetration of mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the evolution of the aggregate number of miners and transactions evolved in the network with respect to the total number of transactions validated (mined). Run the cell below to plot a graph that shows this comparisson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create series with number of miners and transactions\n",
    "no_miners=[len(miner_summary) for miner_summary in miner_summaries]\n",
    "no_transactions=[miner_summary['transaction_count'].sum() for miner_summary in miner_summaries]\n",
    "\n",
    "# Plot\n",
    "y_pos = np.arange(len(no_miners))\n",
    "fig,ax=plt.subplots(figsize=(10,10))\n",
    "\n",
    "ax1 = ax.twinx()\n",
    "fig.suptitle('Miner evolution: miners and transactions',fontsize=20)\n",
    "\n",
    "ax.bar(y_pos,no_miners)\n",
    "ax1.plot(no_transactions,color='r')\n",
    "\n",
    "ax.set_xlabel('Period',fontsize=16)\n",
    "ax.set_ylabel('Number of miners', color='b',fontsize=16)\n",
    "ax1.set_ylabel('Transactions mined', color='r',fontsize=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a similar graph that shows how the number of blocks mined and the number of miners have evolved over the 50 periods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create series with number of miners and transactions\n",
    "no_miners=[len(miner_summary) for miner_summary in miner_summaries]\n",
    "no_transactions=[miner_summary['block'].sum() for miner_summary in miner_summaries]\n",
    "\n",
    "# Plot\n",
    "y_pos = np.arange(len(no_miners))\n",
    "fig,ax=plt.subplots(figsize=(10,10))\n",
    "\n",
    "ax1 = ax.twinx()\n",
    "fig.suptitle('Miner evolution: miners and blocks',fontsize=20)\n",
    "\n",
    "ax.bar(y_pos,no_miners)\n",
    "ax1.plot(no_transactions,color='r')\n",
    "\n",
    "ax.set_xlabel('Period',fontsize=16)\n",
    "ax.set_ylabel('Number of miners', color='b',fontsize=16)\n",
    "ax1.set_ylabel('Number of blocks mined', color='r',fontsize=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION 1**: Give one reason that explains why the growth rate in the number of blocks mined is different from the growth rate of the number of transactions mined. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that the aggregate number of miners has grown slower than the aggregate number of transactions validated, meaning that as the Ethereum Blockchain has progressed, on average each miner must be validating more transactions. Let's take a look at how the proportion of blocks mined by the the top 10 miners (in terms of blocks mined), has evolved over time. Every snapshot has the miners ordered by the number of blocks they have mined. \n",
    "\n",
    "Below we will create a list with the mining share for each miner over the 50 periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extract addresses for top 10 miners\n",
    "\n",
    "top10_miners=miner_summaries[-1].iloc[:10,:]['miner'] # Addresses for top 10 miners\n",
    "\n",
    "# Create a list of lists for each miner to track their mining share across periods \n",
    "\n",
    "top10_per_list=[] \n",
    "for miner in top10_miners:\n",
    "    miner_per_list=[]\n",
    "    for summary in miner_summaries:\n",
    "        try: \n",
    "            blocks_mined=summary.loc[summary['miner']==miner]['block'].values[0]\n",
    "        except IndexError: # Catch error if miner has not appeared in slice\n",
    "            blocks_mined=0 \n",
    "\n",
    "        miner_share=blocks_mined/summary['block'].sum()\n",
    "        miner_per_list.append(miner_share)\n",
    "                   \n",
    "        \n",
    "    top10_per_list.append(miner_per_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Stack Plot\n",
    "fig,ax=plt.subplots(figsize=(10,10))\n",
    "fig.suptitle('% of total Blocks mined by miners that are currently in top 10',fontsize=20)\n",
    "\n",
    "x=np.arange(len(miner_summaries))\n",
    "ax.stackplot(x, *top10_per_list)\n",
    "\n",
    "ax.set_xlabel('Period',fontsize=16)\n",
    "ax.set_ylabel('% Share of blocks mined',fontsize=16)\n",
    "ax.set_ylim(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the top 10 miners, ever since roughly the 5th period (approximately the 5th month), have mined more than 50% of the blocks in Ethereum. We can see the top 10 miners below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miner_summaries[50].head(-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which miner has lost the most 'mining share' between period 10 and 50? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences=[]\n",
    "for miner in top10_per_list:\n",
    "    difference_i=miner[50]-miner[10]\n",
    "    differences.append(difference_i)\n",
    "min_gain_miner=np.array(differences).argmin()\n",
    "print(miner_summaries[50].iloc[min_gain_miner]['miner'])    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**: What is the 'public' name of the miner (mining operation) found in the previous question? (**hint**: Use the miners address and look it up in your favorite block explorer (eg. [Etherscan](https://etherscan.io/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Pre-processing -> Graph definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we're going to pre-process data in a format that is suitable to create a NetworkX Graph object. NetworkX is a library that provides a large array of Network Analysis functions. \n",
    "\n",
    "**Miner transaction graph**\n",
    "\n",
    "For this example we're going to create a directed weighted graph as follows: \n",
    "\n",
    "- Every node in our graph will a miner that has mined a block within our period of analysis (up to block no. 8,863,264). \n",
    "- For every pair of nodes _u_ and _v_ we will define an edge _(u,v)_ if there has been at least one transaction from _u_ and _v_. \n",
    "- We will assign every edge _(u,v)_ a weight corresponding to the total value (in USD) transacted from node _u_ to node _v_\n",
    "\n",
    "**Data**\n",
    "\n",
    "The whole transaction table from BiqQuery for our period of analysis weights more than 250GB, so we went ahead and extracted only the transactions between miners and summarized in the miners_transactions numpy array. This array contains edges between nodes for every snapshot but we will only be looking at the final snapshot for  this section. We also load a more complete version of the final snapshot of miner sumaries on the DataFrame miners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the final snapshot of edges\n",
    "\n",
    "miners=pd.read_csv('./data/miners_summary.csv')\n",
    "miners['miner_id']=miners.index\n",
    "miners_transactions=np.load('./data/miners_trans_evolution_usd.npy',allow_pickle=True)[-1]\n",
    "\n",
    "# Add miner id and change index\n",
    "miners['miner_id']=miners.index #Use index of sorted dataframe (ranking) as miner_id\n",
    "miners=miners.rename(columns={\"count\": \"no. blocks\", \"sum\": \"no. transactions\",\"nunique\": \"unique tags\",'max':'miner_tag'})\n",
    "\n",
    "# Additional transformations for edge calculations\n",
    "miners.set_index('miner',inplace=True) #Set address as index\n",
    "miners['miner']=miners.index\n",
    "miners.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miners.iloc[10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create list of nodes. Given that each address is 20bytes long and we want our graph to be small and provide easily interpretable results, we will want to change the node id, from being the address to something else. For this section will use as node id, the index from the dataframe in the last snapshot. Create a list containing all node ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes=list(miners['miner_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each entry of the miners_transactions array above sumarizes transactions for a pair of addresses in the form \\[\\[address1\\]\\[address2\\],value_transacted,number_of_transactions\\]. The following block of code splits transactions into separate addresses and looks for the miner id in the miners DataFrame, to create a list of tuples of the form (address1_id,address2_id) for each transaction pair. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform concatenation into tuple of miner ids\n",
    "# Extract array\n",
    "address_ex=miners_transactions[:,0] \n",
    "address_ex=address_ex.astype(np.str)\n",
    "\n",
    "# Split strings into two separate lists: join_list_0 and join_list_1\n",
    "split_ad=np.char.rpartition(address_ex,'0x')\n",
    "split_ad_m=np.split(split_ad,[1,2],axis=1) \n",
    "join=np.core.defchararray.add(split_ad_m[1],split_ad_m[2])\n",
    "join_0=np.squeeze(split_ad_m[0])\n",
    "join_list_0=[miners.miner_id[address] for address in join_0]\n",
    "join=np.squeeze(join)\n",
    "join_list_1=[miners.miner_id[address] for address in join ]\n",
    "\n",
    "# Create array of unique edges and edge_weights (undirected graph) to feed to Graph definition \n",
    "tuples=zip(join_list_0,join_list_1)\n",
    "tuples_list=[(a,b) for a,b in tuples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create our graph object we want to to create a list of edges, where each edge _(u,v)_ is a tuple of the form (\\[id_node_u\\],\\[id_node_v\\],{'value':\\[value\\]}). The previous code block created a list of tuples. Using that list and the miner_transactions array create a list of edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges=[(e[0],e[1],{'value':v}) for e,v in zip(tuples_list,miners_transactions[:,1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the list of nodes and edges we can now proceed to define a [NetworkX](https://networkx.github.io/documentation/stable/reference/introduction.html) directed graph _G_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Graph from a NetworkX graph object\n",
    "G=nx.DiGraph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(edges)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Graph visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our transaction Graph defined we can now proceed to visualize it. Run the next cell to define a helper graphing function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_2node_graph(fig,G,nodes_1,nodes_2,edges,edge_width_v,subplot_q,edge_type='',max_sample=1000):\n",
    "\n",
    "    # Sample a max of 5000 edges to reduce plotting time and increase visibility\n",
    "    init_edges=len(edges)\n",
    "    if init_edges>max_sample:\n",
    "        edges=random.sample(list(edges), max_sample)\n",
    "    trimmed_edges=len(edges)\n",
    "\n",
    "\n",
    "    # Define circular layout \n",
    "    pos_o=nx.spring_layout(nodes_1, scale=1,center=(-4,0))\n",
    "    pos_n=nx.spring_layout(nodes_2, scale=0.9,center=(4,0))\n",
    "    total_pos=pos_o\n",
    "    total_pos.update(pos_n)\n",
    "\n",
    "\n",
    "    # Define transactions to show (incoming edges)\n",
    "\n",
    "    values=np.array([d[edge_width_v] for _,_,d in edges])\n",
    "    max_value=np.max(values)\n",
    "    values=values/max_value\n",
    "    values_per=np.array([percentileofscore(values,v,'rank') for v in values])/100\n",
    "\n",
    "    \n",
    "    # Draw nodes and edges\n",
    "    ax=fig.add_subplot(subplot_q)\n",
    "    ax.title.set_text('Transaction Graph')\n",
    "    nx.draw_networkx_nodes(G, total_pos, nodelist=nodes_1, node_size=1, node_color='blue', alpha=0.3)\n",
    "    nx.draw_networkx_nodes(G, total_pos, nodelist=nodes_2, node_size=2, node_color='red', alpha=0.5)\n",
    "    nx.draw_networkx_edges(G,total_pos,edgelist=edges,alpha=0.1,width=values_per)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will break up the graph by showing transactions within and between two groups of nodes: the top 10 miners and the rest. In the following block fill in the code to define a list for each one of the groups. (Running the next cell might take between 2-5 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(18,18))\n",
    "\n",
    "# Define lists for top 10 miners 'nodes_1' and the rest 'nodes_2'. Remember that the DataFrame them \n",
    "# in order of mining power. \n",
    "nodes_1=miners['miner_id'][:10].tolist()\n",
    "nodes_2=miners['miner_id'][10:].tolist()\n",
    "\n",
    "draw_2node_graph(fig,G,nodes_1,nodes_2,G.edges(data=True),'value',111,edge_type='',max_sample=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph plotted above shows the top 10 miners on the left and the rest on the right. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Network analysis metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the last part of the Homework we're going to run some basic network analysis metrics using the NetworkX library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Degree**: The following function calculates the weighted in-degree and out degrees for every node in the graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_indegree=list(G.in_degree(G.nodes(),weight='value'))\n",
    "G_outdegree=list(G.out_degree(G.nodes(),weight='value'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the average in_degree and out_degree values for nodes in the graph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_indegree=np.array([degree for node,degree in G_indegree]).mean()\n",
    "mean_outdegree=np.array([degree for node,degree in G_outdegree]).mean()\n",
    "\n",
    "print('Mean in-degree:{}'.format(mean_indegree))\n",
    "print('Mean out-degree:{}'.format(mean_outdegree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**: What is the relationship between the two values calculated above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Density**: The following function calculates de density for graph G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_final=nx.classes.function.density(G)\n",
    "print('Density for graph G is: {}'.format(density_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4**: How do you interpret the number above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Strongly connected components**: The code block below extracts the strongly connected components of the transaction graph. Remember that strongly connected components of a directed graph are the subsets of the nodes in the graph in which any node can be reached by any other by traversing the existing edges. The implementation of NetworkX returns the strongly connected components in order of size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What percentage of the nodes in the graph are in the largest strongly connected component?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_scc=nx.strongly_connected_components(G)\n",
    "\n",
    "large_scc=max(G_scc, key=len)\n",
    "proportion_SCC=len(large_scc)/len(G.nodes())\n",
    "print('{:3f}% of the nodes are in the larges SCC:'.format(proportion_SCC*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations! \n",
    "You have ran through the notebook and learned how to analyze blockchain data! \n",
    "\n",
    "Please submit the screenshot of your graph and the answers to the conceptual questions following the instruction on course repo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
